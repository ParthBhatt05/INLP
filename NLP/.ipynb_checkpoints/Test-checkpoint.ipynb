{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indian Natural Language Processing Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the _INLP Library_ is to build Python based libraries for common text processing and Natural Language Processing in Indian languages. Indian languages share a lot of similarity in terms of script, phonology, language syntax, etc. and this library is an attempt to provide a general solution to very commonly required toolsets for Indian language text. \n",
    "\n",
    "The library provides the following functionalities: \n",
    "\n",
    "- Text Normalization\n",
    "- Script Conversion\n",
    "- Romanization\n",
    "- Indicization\n",
    "- Script Information\n",
    "- Phonetic Similarity\n",
    "- Syllabification\n",
    "- Tokenization\n",
    "- Word Segmenation\n",
    "- Transliteration\n",
    "- Translation\n",
    "\n",
    "The data resources required by the INLP Library are hosted in a different repository. These resources are required for some modules. You can download from the [Indian Natural Language Processing Resources](https://github.com/parthbhatt05/INLP/resources) project.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "- Python 2.7+\n",
    "- [Morfessor 2.0 Python Library](http://www.cis.hut.fi/projects/morpho/morfessor2.shtml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  ----- Set these variables ----- **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the local git repo for INLP library\n",
    "INLP_NLP_LIB_HOME=\"C:\\Users\\Parth\\Documents\\CC\\NLP\"\n",
    "\n",
    "# The path to the local git repo for INLP Resources\n",
    "INLP_NLP_RESOURCES=\"C:\\Users\\Parth\\Documents\\CC\\NLP_Resources\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Library to Python path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('{}/src'.format(INLP_NLP_LIB_HOME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Export environment variable ** \n",
    "\n",
    "    export INLP_RESOURCES_PATH=<path>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     OR\n",
    "     \n",
    "**set it programmatically**\n",
    "We will use that method for this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inlp import common\n",
    "common.set_resources_path(INLP_NLP_RESOURCES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Initialize the INLP library **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inlp import common\n",
    "from src.inlp.script import indian_language_scripts\n",
    "from src.inlp.script import english_script\n",
    "common.init()\n",
    "indian_language_scripts.init()\n",
    "english_script.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let's actually try out some of the API methods in the INLP library **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the API functions require a language code. We use 2-letter ISO 639-1 codes. Some languages do not have assigned 2-letter codes. We use the following two-letter codes for such languages: \n",
    "\n",
    "- Hindi: hi\n",
    "- Gujarati: gu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "\n",
    "Text written in Indian scripts display a lot of quirky behaviour on account of varying input methods, multiple representations for the same character, etc. \n",
    "There is a need to canonicalize the representation of text so that NLP applications can handle the data in a consistent manner. The canonicalization primarily handles the following issues: \n",
    "\n",
    "    - Non-spacing characters like ZWJ/ZWNL\n",
    "    - Multiple representations of Nukta based characters \n",
    "    - Multiple representations of two part dependent vowel signs\n",
    "    - Typing inconsistencies: e.g. use of pipe (|) for poorna virama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "क़ क़\n",
      "Length before normalization: 4\n",
      "Length after normalization: 5\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.normalize.normalize import IndianLanguageNormalizerFactory\n",
    "\n",
    "input_text=u\"\\u0958 \\u0915\\u093c\"\n",
    "remove_nuktas=False\n",
    "factory=IndianLanguageNormalizerFactory()\n",
    "normalizer=factory.get_normalizer(\"hi\",remove_nuktas)\n",
    "output_text=normalizer.normalize(input_text)\n",
    "\n",
    "print output_text\n",
    "print 'Length before normalization: {}'.format(len(input_text))\n",
    "print 'Length after normalization: {}'.format(len(output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Conversion\n",
    "\n",
    "Convert from one Indian script to another. This is a simple script which exploits the fact that Unicode points of various Indian scripts are at corresponding offsets from the base codepoint for that script. The following scripts are supported:\n",
    "\n",
    "_Devanagari: Hindi, Gujarati_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "પાર્થ\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.transliterate.unicode_transliterate import UnicodeIndianLanguageTransliterator\n",
    "input_text=u'पार्थ'\n",
    "print UnicodeIndianLanguageTransliterator.transliterate(input_text,\"hi\",\"gu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Romanization\n",
    "\n",
    "Convert script text to Roman text in the ITRANS notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pArtha\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.transliterate.unicode_transliterate import ItransTransliterator\n",
    "\n",
    "input_text=u'पार्थ'\n",
    "lang='hi'\n",
    "\n",
    "\n",
    "print ItransTransliterator.to_itrans(input_text,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indianization (ITRANS to Indian Script)\n",
    "\n",
    "Let's call conversion of ITRANS-transliteration to an Indian script as **Indianization**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "पार्थ्\n",
      "92a\n",
      "93e\n",
      "930\n",
      "94d\n",
      "925\n",
      "94d\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.transliterate.unicode_transliterate import ItransTransliterator\n",
    "\n",
    "\n",
    "input_text=u'pArth'\n",
    "lang='hi'\n",
    "x=ItransTransliterator.from_itrans(input_text,lang)\n",
    "print x\n",
    "for y in x:\n",
    "    print '{:x}'.format(ord(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Information\n",
    "\n",
    "Indian scripts have been designed keeping phonetic principles in nature and the design and organization of the scripts makes it easy to obtain phonetic information about the characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Phonetic Feature Vector\n",
    "\n",
    "With each script character, a phontic feature vector is associated, which encodes the phontic properties of the character. This is a bit vector which is can be obtained as shown below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.inlp.script import  indian_language_scripts as isc\n",
    "\n",
    "c=u'क'\n",
    "lang='hi'\n",
    "\n",
    "isc.get_phonetic_feature_vector(c,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fields in this bit vector are (from left to right): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('basic_type', [0, 6]),\n",
       " ('vowel_length', [6, 8]),\n",
       " ('vowel_strength', [8, 11]),\n",
       " ('vowel_status', [11, 13]),\n",
       " ('consonant_type', [13, 18]),\n",
       " ('articulation_place', [18, 23]),\n",
       " ('aspiration', [23, 25]),\n",
       " ('voicing', [25, 27]),\n",
       " ('nasalization', [27, 29]),\n",
       " ('vowel_horizontal', [29, 32]),\n",
       " ('vowel_vertical', [32, 36]),\n",
       " ('vowel_roundness', [36, 38])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(isc.PV_PROP_RANGES.iteritems(),key=lambda x:x[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the phonetic information database files in INLP resources to know the definition of each of the bits. \n",
    "\n",
    "- _For Tamil Script_: [database](https://github.com/parthbhatt05/INLP/resources/blob/master/script/tamil_script_phonetic_data.csv) \n",
    "- _For other Indian Scripts_: [database](https://github.com/parthbhatt05/INLP/blob/master/script/all_script_phonetic_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Phonetic Properties\n",
    "\n",
    "**Note:** _This interface below will be deprecated soon and a new interface will be available soon._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is vowel?:  False\n",
      "Is consonant?:  True\n",
      "Is velar?:  True\n",
      "Is palatal?:  False\n",
      "Is aspirated?:  False\n",
      "Is unvoiced?:  True\n",
      "Is nasal?:  False\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.language_info import *\n",
    "\n",
    "c=u'क'\n",
    "lang='hi'\n",
    "\n",
    "print 'Is vowel?:  {}'.format(is_vowel(c,lang))\n",
    "print 'Is consonant?:  {}'.format(is_consonant(c,lang))\n",
    "print 'Is velar?:  {}'.format(is_velar(c,lang))\n",
    "print 'Is palatal?:  {}'.format(is_palatal(c,lang))\n",
    "print 'Is aspirated?:  {}'.format(is_aspirated(c,lang))\n",
    "print 'Is unvoiced?:  {}'.format(is_unvoiced(c,lang))\n",
    "print 'Is nasal?:  {}'.format(is_nasal(c,lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Phonetic Similarity\n",
    "\n",
    "Using the phonetic feature vectors, we can define phonetic similarity between the characters (and underlying phonemes). The library implements some  measures for phonetic similarity between the characters (and underlying phonemes). These can be defined using the phonetic feature vectors discussed earlier, so users can implement additional similarity measures. \n",
    "\n",
    "The implemented similarity measures are: \n",
    "\n",
    "- cosine\n",
    "- dice\n",
    "- jaccard\n",
    "- dot_product\n",
    "- softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between क and ख\n",
      "0.833331944447\n",
      "\n",
      "Similarity between क and भ\n",
      "0.499999166668\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.script import  indian_language_scripts as isc\n",
    "from src.inlp.script import  phonetic_sim as psim\n",
    "\n",
    "c1=u'क'\n",
    "c2=u'ख'\n",
    "c3=u'भ'\n",
    "lang='hi'\n",
    "\n",
    "print u'Similarity between {} and {}'.format(c1,c2)\n",
    "print psim.cosine(\n",
    "    isc.get_phonetic_feature_vector(c1,lang),\n",
    "    isc.get_phonetic_feature_vector(c2,lang)\n",
    "    )\n",
    "\n",
    "print\n",
    "\n",
    "print u'Similarity between {} and {}'.format(c1,c3)\n",
    "print psim.cosine(\n",
    "    isc.get_phonetic_feature_vector(c1,lang),\n",
    "    isc.get_phonetic_feature_vector(c3,lang)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_You may have figured out that you can also compute similarities of characters belonging to different scripts._\n",
    "\n",
    "You can also get a similarity matrix which contains the similarities between all pairs of characters (within the same script or across scripts).\n",
    "\n",
    "Let's see how we can compare the characters across Hindi and Gujarati scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between क and ક\n",
      "0.999998333336\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.script import  indian_language_scripts as isc\n",
    "from src.inlp.script import  phonetic_sim as psim\n",
    "\n",
    "\n",
    "slang='hi'\n",
    "tlang='gu'\n",
    "sim_mat=psim.create_similarity_matrix(psim.cosine,slang,tlang,normalize=False)\n",
    "\n",
    "c1=u'क'\n",
    "c2=u'ક'\n",
    "print u'Similarity between {} and {}'.format(c1,c2)\n",
    "print sim_mat[isc.get_offset(c1,slang),isc.get_offset(c2,tlang)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some similarity functions like `sim` do not generate values in the range [0,1] and it may be more convenient to have the similarity values in the range [0,1]. This can be achieved by setting the `normalize` paramter to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between क and ખ\n",
      "0.0686089400193\n"
     ]
    }
   ],
   "source": [
    "slang='hi'\n",
    "tlang='gu'\n",
    "sim_mat=psim.create_similarity_matrix(psim.sim1,slang,tlang,normalize=True)\n",
    "\n",
    "c1=u'क'\n",
    "c2=u'ખ'\n",
    "print u'Similarity between {} and {}'.format(c1,c2)\n",
    "print sim_mat[isc.get_offset(c1,slang),isc.get_offset(c2,tlang)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthographic Syllabification\n",
    "\n",
    "_Orthographic Syllabification_ is an approximate syllabification process for Indic scripts, where CV+ units are defined to be _orthographic syllables_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "न रे ंद्र   कु मा र\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.syllable import  syllabifier\n",
    "\n",
    "w=u'नरेंद्र कुमार'\n",
    "lang='hi'\n",
    "\n",
    "print u' '.join(syllabifier.orthographic_syllabify(w,lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization \n",
    "\n",
    "A trivial tokenizer which just tokenizes on the punctuation boundaries. This also includes punctuations for the Indian language scripts (the purna virama and the deergha virama). It returns a list of tokens.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input String: नमस्ते, मैं पार्थ हूं|\n",
      "Tokens: \n",
      "नमस्ते\n",
      ",\n",
      "मैं\n",
      "पार्थ\n",
      "हूं\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "from src.inlp.tokenize import tokenize  \n",
    "\n",
    "i_string=u'नमस्ते, मैं पार्थ हूं|'\n",
    "\n",
    "print u'Input String: {}'.format(i_string)\n",
    "print u'Tokens: '\n",
    "for t in tokenize.trivial_tokenize(i_string): \n",
    "    print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Segmentation\n",
    "\n",
    "Unsupervised morphological analysers for various Indian language. Given a word, the analyzer returns the componenent morphemes. \n",
    "The analyzer can recognize inflectional and derivational morphemes. \n",
    "\n",
    "The following languages are supported:\n",
    "\n",
    "_Hindi, Gujarati_\n",
    "\n",
    "Support for more languages will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inlp.morph import morph \n",
    "from src.inlp import common\n",
    "\n",
    "analyzer=morph.UnsupervisedMorphAnalyzer('gu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "આજે\n",
      "હું\n",
      "ઘરે\n",
      "વહેલો\n",
      "જ\n",
      "ઉં\n",
      "છું\n",
      "અને\n",
      "ત્યાં\n",
      "ભોજન\n",
      "કર\n",
      "ું\n",
      "છું\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "string=u'આજે હું ઘરે વહેલો જઉં છું અને ત્યાં ભોજન કરું છું .'\n",
    "\n",
    "analyzes_tokens=analyzer.morph_analyze_document(string.split(' '))\n",
    "\n",
    "for w in analyzes_tokens: \n",
    "    print w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inlp.transliterate import itrans_transliterator\n",
    "from inlp.transliterate import unicode_transliterate\n",
    "from inlp.normalize import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "चक्र\n"
     ]
    }
   ],
   "source": [
    "print itrans_transliterator.transliterate('chakra', 'itrans',\n",
    "                        'devanagari', {'outputASCIIEncoded' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "હુ કલે બર્ ગયો હતો, અને બવ્ મજ કરિ\n"
     ]
    }
   ],
   "source": [
    "text='hu kale bar gayo hato, ane bav maja kari'\n",
    "print unicode_transliterate.ItransTransliterator.from_itrans(text,'gu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aje huM ghare vahelo juM ChuM ane tyAM bhojana karuM ChuM\n"
     ]
    }
   ],
   "source": [
    "text=u'આજે હું ઘરે વહેલો જઉં છું અને ત્યાં ભોજન કરું છું'\n",
    "lang='gu'\n",
    "\n",
    "n=normalize.IndianLanguageNormalizerFactory().get_normalizer(lang)\n",
    "text=n.normalize(text)\n",
    "\n",
    "print unicode_transliterate.ItransTransliterator.to_itrans(text,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "પ aaa\n",
      "ા abe\n",
      "ર ab0\n",
      "્ acd\n",
      "થ aa5\n"
     ]
    }
   ],
   "source": [
    "x=u'પાર્થ'\n",
    "\n",
    "for c in x:\n",
    "    print u'{} {:x}'.format(c,ord(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [_BrahmiNet_](http://www.cfilt.iitb.ac.in/brahminet/static/rest.html) REST API for transliteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from django.utils.encoding import * \n",
    "from django.utils.http import * \n",
    "\n",
    "text=iri_to_uri(urlquote('parth, kushan kal fone par baat kar rahe the'))\n",
    "url=u'http://www.cfilt.iitb.ac.in/inlpweb/inlpws/transliterate_bulk/en/hi/{}/statistical'.format(text)\n",
    "\n",
    "response=urllib2.urlopen(url).read()\n",
    "print response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use _BrahmiNet_ through [this](http://www.cfilt.iitb.ac.in/brahminet) web interface.  \n",
    "\n",
    "You can read more about _BrahmiNet_ [here](http://www.cfilt.iitb.ac.in/brahminet/static/publications/brahminet_naacl2015.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
